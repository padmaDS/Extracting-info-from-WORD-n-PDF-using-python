{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2 pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjt60-KTI5EX",
        "outputId": "96ca7936-3a37-4750-bf2f-4c64d4dcb476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20221105)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2"
      ],
      "metadata": {
        "id": "3cYUaww3JRn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/drive/MyDrive/Data Science/Resume-Prashanth-2023.pdf\""
      ],
      "metadata": {
        "id": "vFIPU6cZJVHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## with open(pdf_path, \"rb\") as pdf_file:\n",
        "#    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "#    for page_num in range(len(pdf_reader.pages)):\n",
        "#        page = pdf_reader.pages[page_num]\n",
        "#       text = page.extract_text()\n",
        "#       print(text)"
      ],
      "metadata": {
        "id": "2-ORZWklJISO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "pdf_path = \"/content/drive/MyDrive/Data Science/RESUME_NILAM.pdf\"\n",
        "\n",
        "text = extract_text(pdf_path)\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjn8PN6RJYdW",
        "outputId": "5e5b1d4b-a823-4e5d-b829-acea87c72742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nilam Sonawane\n",
            "\n",
            "Data Scientist\n",
            "\n",
            "Contact\n",
            "\n",
            "TECHNICAL PROJECTS\n",
            "\n",
            "nilamds0411@gmail.com\n",
            "\n",
            "7447220690\n",
            "\n",
            "Pune, Maharashtra\n",
            "\n",
            "https://www.linkedin.com/in/nil\n",
            "am-sonawane-a9b8b6251/\n",
            "\n",
            "About Me\n",
            "\n",
            "A data science professional with an overall \n",
            "experience of 3 years in the Information Technology,\n",
            "Automobile, E-Commerce and services industry. \n",
            "Skilled in Python (Programming Language), Data\n",
            "Science, Data Pre-processing, Data Modelling,\n",
            "Visualization, Machine Learning, SQL, Hadoop and NLP.\n",
            "Strong analytical, mathematical and statistical skills.\n",
            "Strong team working spirit as well as individual\n",
            "contributor.\n",
            "Willing to learn and explore new technologies.\n",
            "\n",
            "Professional Experience\n",
            "\n",
            "Data Scientist\n",
            "Zopper Solutions Pvt. Ltd.      Jan 2021- Present\n",
            "\n",
            "1. Develop | Build | Manage | Data Capability \n",
            "products and services \n",
            "2. Assisting and Managing Standard \n",
            "Operating Procedure (SOP) & Turn Around \n",
            "Time (TAT) \n",
            "\n",
            "Data Science Intern\n",
            "Bluebox Technologies Pvt. Ltd.      \n",
            "May 2020 – Nov 2020\n",
            "\n",
            "1. Participated in Data science internship \n",
            "having focus on core domain of DS and \n",
            "ML Algorithms.\n",
            "2. Performed EDA on different datasets \n",
            "from finance, healthcare domain.\n",
            "\n",
            "1.Title : Predictive model for automotive industry  \n",
            "(Dec 2022 –Present)\n",
            "\n",
            "· Researched and developed statistical learning\n",
            "models for analysis of automobile dataset.\n",
            "· Did data visualization through histogram to get\n",
            "graphical representation of fuel consumed in vehicles,\n",
            "cylinders, size of engines etc.\n",
            "· Trained the model on supervised machine learning\n",
            "algorithms and predicted the system on test data.\n",
            "· Depicted graphs of predicted vs actual CO2 values\n",
            "with various estimators.\n",
            ".\n",
            "\n",
            "2.Title : Bank loan prediction system. \n",
            "(Jan 2022- Nov 2022)\n",
            "\n",
            "· Collaborated with stakeholders and team leads in\n",
            "order to understand problem statements and design\n",
            "and execute potential solutions.\n",
            "· Performed exploratory Data Analysis on data sets\n",
            "comprising of structured and semi-structured data.\n",
            "· Selected features on the basis of relation with loan\n",
            "approval.\n",
            "· Trained the model on supervised machine learning\n",
            "algorithms and predicted the system on test data.\n",
            "· Correlation between the different parameters of\n",
            "model is graphically visualized.\n",
            "\n",
            "3.Title : E-Commerce Sales Forecast \n",
            "(February 2021-October 2021)\n",
            "\n",
            "· Researched and developed statistical learning\n",
            "models for analysis of e-Commerce dataset.\n",
            "· Cleaned and filtered data according to the\n",
            "requirement.\n",
            "Did data visualization through histogram to get\n",
            "graphical representation.\n",
            "· Trained the model on supervised machine learning\n",
            "algorithms and predicted the system on test data.\n",
            "\n",
            "\fTECHNICAL SKILLS\n",
            "\n",
            "PERSONAL ACHIEVEMENTS\n",
            "\n",
            "Languages & Tools:\n",
            "\n",
            "Python\n",
            "\n",
            "Databases:\n",
            "\n",
            "SQL Server 2008\n",
            "\n",
            "1. Awarded by Rajya Puraskar in Scouts and \n",
            "Guides.\n",
            "2. Regional level Basketball and Handball Player.\n",
            "3. District level Table Tennis Player.\n",
            "4. Member of Maharashtra Women's Cricket \n",
            "League 2022. \n",
            "\n",
            "Data Science\n",
            "Libraries\n",
            "\n",
            "Numpy, Pandas, seaborn,\n",
            "matplotlib, sklearn,\n",
            "scikitlearn\n",
            "\n",
            "ML Algorithms\n",
            "\n",
            "Linear Regression, Logistic\n",
            "Regression, Decision Tree,\n",
            "Random Forest, KNN, Naïve\n",
            "Bayes, K-means clustering\n",
            "\n",
            "DL Algorithms\n",
            "\n",
            "ANN, RNN, CNN\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Savitribai Phule, Pune University\n",
            "BE (2016-2020) \n",
            "Graduated with Distinction\n",
            "\n",
            "Jawahar Navodaya Vidyalaya, Raigad\n",
            "HSC - 2016 \n",
            "Graduated with Distinction\n",
            "\n",
            "Jawahar Navodaya Vidyalaya, Raigad\n",
            "SSC-2014 \n",
            "Graduated with Distinction\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3I78V1_jLWgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jpIaThm2PFdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oe-h13UjPFnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1d0rAiGPFqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extracting from Word"
      ],
      "metadata": {
        "id": "nbgwwX3ePJPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tj_V5m2PMoU",
        "outputId": "b23fc94d-3826-4d57-f0cc-343e3f0ae3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (0.8.11)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx"
      ],
      "metadata": {
        "id": "-xMmrgPBPVt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_path = \"/content/drive/MyDrive/Data Science/Anuradha_Datascience_4.5yrs+CV.docx\"\n"
      ],
      "metadata": {
        "id": "IJt26eayPP7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = docx.Document(doc_path)\n"
      ],
      "metadata": {
        "id": "fb59lDxhPb4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headings_and_text = []\n",
        "\n",
        "current_heading = None\n",
        "paragraph_text = \"\"  # Initialize paragraph_text here\n",
        "\n",
        "for paragraph in doc.paragraphs:\n",
        "    if paragraph.style.name.startswith(\"Heading\"):\n",
        "        if current_heading is not None:\n",
        "            headings_and_text.append((current_heading, paragraph_text))\n",
        "        current_heading = paragraph.text\n",
        "        paragraph_text = \"\"  # Reset paragraph_text for the new section\n",
        "    else:\n",
        "        paragraph_text += paragraph.text + \"\\n\"\n",
        "\n",
        "# Append the last heading and text\n",
        "if current_heading is not None:\n",
        "    headings_and_text.append((current_heading, paragraph_text))\n",
        "\n",
        "# Print or process the extracted headings and text\n",
        "for heading, text in headings_and_text:\n",
        "    print(\"Heading:\", heading)\n",
        "    print(\"Text:\", text)\n"
      ],
      "metadata": {
        "id": "QYa6gFK7X7Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_path1 = \"/content/drive/MyDrive/Data Science/Anuradha_Datascience_4.5yrs+CV.docx\"\n"
      ],
      "metadata": {
        "id": "NXambjKSczUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = docx.Document(doc_path1)"
      ],
      "metadata": {
        "id": "AiT2y6nqczZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headings_and_text = []\n",
        "\n",
        "current_heading = None\n",
        "paragraph_text = \"\"  # Initialize paragraph_text here\n",
        "\n",
        "for paragraph in doc1.paragraphs:\n",
        "    if paragraph.style.name.startswith(\"Heading\"):\n",
        "        if current_heading is not None:\n",
        "            headings_and_text.append((current_heading, paragraph_text))\n",
        "        current_heading = paragraph.text\n",
        "        paragraph_text = \"\"  # Reset paragraph_text for the new section\n",
        "    else:\n",
        "        paragraph_text += paragraph.text + \"\\n\"\n",
        "\n",
        "# Append the last heading and text\n",
        "if current_heading is not None:\n",
        "    headings_and_text.append((current_heading, paragraph_text))\n",
        "\n",
        "# Print or process the extracted headings and text\n",
        "for heading, text in headings_and_text:\n",
        "    print(\"Heading:\", heading)\n",
        "    print(\"Text:\", text)\n"
      ],
      "metadata": {
        "id": "t305hYnXZI6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "doc_path = \"/content/drive/MyDrive/Data Science/Resume_Tapabrata.docx\"\n",
        "doc = docx.Document(doc_path)\n",
        "\n",
        "headings_and_text = []\n",
        "\n",
        "current_heading = None\n",
        "paragraph_text = \"\"  # Initialize paragraph_text here\n",
        "\n",
        "for paragraph in doc.paragraphs:\n",
        "    if paragraph.style.name.startswith(\"Heading\"):\n",
        "        if current_heading is not None:\n",
        "            headings_and_text.append((current_heading, paragraph_text))\n",
        "        current_heading = paragraph.text\n",
        "        paragraph_text = \"\"  # Reset paragraph_text for the new section\n",
        "    else:\n",
        "        paragraph_text += paragraph.text + \"\\n\"\n",
        "\n",
        "# Append the last heading and text\n",
        "if current_heading is not None:\n",
        "    headings_and_text.append((current_heading, paragraph_text))\n",
        "\n",
        "# Print or process the extracted headings and text\n",
        "for heading, text in headings_and_text:\n",
        "    print(\"Heading:\", heading)\n",
        "    print(\"Text:\", text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZXC-RpRWVKY",
        "outputId": "2e29bede-1d5e-42bb-eca5-f08d08d38791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heading: Professional summary:\n",
            "Text: \n",
            "Data Scientist with 13+ years (7 years in ML) working experince in Machine Learning , Transfer Learning ,Computer Visions, NLP,Neural Network , ETL, Teradata, Tableau solve challenging buisness Problems and draw Buisness insights.\n",
            " \n",
            "\n",
            "Heading: EXPERIENCE:\n",
            "Text: \n",
            "Worked as Software Engineer for CGI , Bangalore from July, 2009 to March, 2013 .\n",
            "Worked as Senior Software Engineer for RS Software , Kolkata from April,2013 to March ,2015(Also deputed in Singapore VISA) .\n",
            "Worked as Sc Data Scientist from 2015 till now.\n",
            "Deputed to  client location (UK TCS) for more than 5 years.\n",
            "\n",
            "\n",
            "\n",
            "Heading: ACADEMIC PROFILE:\n",
            "Text: \n",
            "    Post Graduate Diploma :Advanced Programme in Computational Data Science (IISC Bangalore)     \n",
            "        \n",
            "    Bachelar Degree:       B.Tech  (Computer Science and Engineering WBUT)\n",
            "\n",
            "\n",
            "Heading: SKILL SET:\n",
            "Text: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Heading: Project Experience:\n",
            "Text: \n",
            "Data Scientist (TCS Kolkata & UK): 2015 - Till today\n",
            "Done Twiter sentiment anyalysis POC for small tea/coffee chain(PRET UK) Using Teewpy and NLTK.\n",
            "Ecommerce website product reviews Topic modelling to segrigate review based on there contents.\n",
            "Build customer psychology-based recommendation system for (OTT) Bloomberg Media.\n",
            "Build sentiment anyalisis models from customer comments (Hugging face Bert) on different news articles/videos on (OTT) Bloomberg Media.\n",
            "Build Recommendation eingine for customers for Ecommerce online fashion retail client JDwilliams.\n",
            "Worked on Autoencoder based de-noiseing/colour enhancement of seismic experiment maps to find underground mines & oil field (IISC PG Capstone) .\n",
            "Build customer question answer based chatbot (Hugging face NLP) for Walters Kluers .\n",
            "Build End to End Chatbot using Python and transformer. And tuned & retrained it for Primarks  ecommerce & onlinse stores.\n",
            "Worked on customer churn anyalysis for telecom customers (bagging and boosting model) Vodaphone UK.\n",
            "Build and deployed revenue forecasting (Time Series) model for SPGlobal this model forecast for induvidual salesman as well as entrprise level & Build location geography based recommended product for sales marketing team to maximize the sales & revenue.\n",
            "Building AI based capacity planning for DLR (pyspark, Mlib).\n",
            "Build and deployed credit score & credit-risk (regression based) models for Experian.\n",
            "Build and deployed revenue Demand & Sales forecasting (Time Series) model for multiple UK retailers (Morrisons, JDWilliams & Primark) .\n",
            "Demand and Supply Analysis for Morrisons Supermarket and also build a Demand Forecasting model .\n",
            "Build associative rule mining-based supermarket space planning /range-planner model.\n",
            "Build application-level cloud usage & billinng forecasting model (Time Series) using cloudonomy output to understand mcgraw-hill future spending on cloud services.\n",
            "Build and deployed machine learning projects like customer profiling (Clustering), recommendation system for different UK Retailers (Morrisns,JD Williams & Primark).\n",
            "Analyse data and extract data from Oracle using SQL, AWS (S3), Teradata and Py-Spark, done market basket analysis, associative rule mining and collaborative filtering for Primark.\n",
            "Designed & Built and deployment of various Classification Models for the transactions reported to scale current manual processes and resources to predict Status of the transaction based on business requirements.\n",
            "Developed Programs for Wide Area Network(a.k.a. WAN) capacity management to have a scoring mechanism for Wan health using the Quality of service and Quality of user experience data FOR Vodaphone UK.\n",
            "Developed DWH, data-lakes, tableau dashboard and data stories for multiple customers  .\n",
            "\n",
            "\n",
            "Sc Mainframe Developer (VISA, RS Software): 2013- 2015\n",
            "Understand & Gather requirement after discussion with BA and product owner.\n",
            "Design , build and maintain different MF,Teradata based projects for VISA . \n",
            "Building JCL + Teradata loader jobs to do ETL work for VISA data Warehouse.\n",
            "Update & Adding new rules through changing cobol codes whenever new VISA fees are added.\n",
            "\n",
            "Mainframe & Data Developer (Bell Canada, CGI) : 2009- 2013\n",
            "Coordinating with VISA SME for delivery related issues, helping team and mentoring member on day to day work.\n",
            "Preparing the Low-level Design and coding them on Cobol/CICS as per requirements of project .\n",
            "Unit Testing and genarating Unit testing Reports. \n",
            "Building JCL + Teradata loader jobs to do ETL work for VISA data Warehouse.\n",
            "Building Datastage pipeline to extract data from open system.\n",
            "Updatde & Adding new rules through changing cobol codes whenever new VISA fees are added.\n",
            "\n",
            "\n",
            "\n",
            "Heading: Training & certification Details:\n",
            "Text: \n",
            "Perusing Advanced Program in Computational Data Science (PGDA equivalent) from IISC (Bangalore).  \n",
            "Passed ITIL foundation (2014) certification.\n",
            "Done DB2 730 certification (IBM).\n",
            "Mainframe training from (HTMT Global).\n",
            "B-Tech Final Year vocational training Networking (IIHT).\n",
            "\n",
            "\n",
            "\n",
            "Heading: Personal Details:\n",
            "Text: \n",
            "           Father’s Name                  Mr. Tarasankar Halder.\n",
            "\tDate of Birth                     01-07-1983(dd-mm-yyyy).\n",
            "\tSex\t\t\t     Male.\n",
            "\tMarital Status                   Single.\n",
            "Language Known\t     English, Bengali, Hindi\n",
            "Nationality                        Indian.\n",
            "           Permanent Address           4H block 3 , Maya Complex ,Reckjoani Hospital Road Rajarhat,   \n",
            "                                                   Newtown Kolkata, West Bengal 700135\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZT9rl60eOM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import docx\n",
        "\n",
        "doc_path = \"your_word_document.docx\"\n",
        "\n",
        "doc = docx.Document(doc_path)"
      ],
      "metadata": {
        "id": "SiVDWl2_hchi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_path1 = \"/content/drive/MyDrive/Data Science/Rajesh_Kandukuri_Data_Science.docx\"\n",
        "\n",
        "doc1 = docx.Document(doc_path1)"
      ],
      "metadata": {
        "id": "5BA4P5wqhlZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_text = \"\"\n",
        "\n",
        "for paragraph in doc1.paragraphs:\n",
        "    full_text += paragraph.text + \"\\n\"\n",
        "\n",
        "# Print or process the extracted text\n",
        "print(full_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMj7RqmlhN_-",
        "outputId": "25257546-acab-48b6-e83f-65983ba7970a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rajesh Kandukuri\t\t\t\t\t\t\t\t\t    P: +91-9704548416\n",
            "Parkview Residency, HMT Swarnapuri Colony\tDATA SCIENTIST\t\trajesh.kandukuri8@gmail.com\n",
            "   Hyderabad 500049\t\t\t\tLinkedIn: https://www.linkedin.com/in/rajesh-kandukuri-203119119/\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Certified as Machine Learning & Data Visualization Professional by UpX Academy, Tech Mahindra.\n",
            "\n",
            "Selected Course Work in DATA SCIENCE - Data Science Super Specialization (UpX Academy).\n",
            "\tSelected PROJECTS in DATA SCIENCE\n",
            "\t-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Exploratory Data Analysis Projects\n",
            "Airlines\n",
            "\tDeparture delays, Best airports in terms of time departure %, Aircraft speed analysis, On time arrival \t% analysis, Maximum number of flights headed to some particular destination.\n",
            "Sports\n",
            "\tSummary Stats: Matches, Teams, Referees, %home win, %away win, Relegation Analysis, Best/Worst \tperforming teams, Playing styles: Fouls, Shots.\n",
            "Food & Beverages\n",
            "\tData preparation: dividing quality score into 3 different categories, etc., Visualisations to depict how \tresidual sugar, density, and alcohol affect the quality of wine, Other variable observations, Faulty \tWines: Characteristics that can influence wine quality negatively, Univariate and Bivariate analysis.\n",
            "Automobile\n",
            "\tLoading and cleaning data, Variable analysis to see its impact on automobile pricing, Summary \tStatistics of different variables, Univariate and Bivariate analysis, Make, Curb-weight, Drive wheels \tanalysis\n",
            "Social Network\n",
            "\tDate of birth analysis, Friend count analysis, Tenure analysis, Data transformations, Frequency \tpolygons, Box plots.\n",
            "\n",
            "Machine Learning Projects\n",
            "Banking – Loan Prediction (Output feature – Loan Status)\n",
            "Getting, cleaning, and preparing the data, Visualizing Income vs. Loan Amount, mapping the data, Application of Logistic Regression on Train Test Split of data, Evaluation of the Logistic Regression model with Accuracy Score and ROC-AUC, Found out Decision Tree and Random Forest as more appropriate models with good score.\n",
            "\n",
            "Sales – Nike Sales (Output feature – Sales)\n",
            "Hierarchical Indexing (Year & Quarters), Create a column for quarters as unique identification numbers (time variables), Visualization of Sales throughout the period in data, Prediction of Sales with Linear Regression (input feature is time variable), Evaluate the model with RMSE compared to Null RMSE, Calculate fractions with actual Sales and Predicted Sales, Use the quarterly average of fractions with the fitted Linear Regression Model to predict the Sales for future quarters.\n",
            "\n",
            "Telecom – Telecom Churn (Output feature – Churn status)\n",
            "Getting the data, Name the columns in the dataset, Cleaning and preparing the data, See the correlation between features using the Heat map of Correlation matrix, Fitting the data with Logistic Regression, Decision Tree, and Random Forest, Checking the average score of fitted Logistic Regression with Cross Validation, Checking the scores of Decision Tree model and Random Forest model, Checking the Confusion Matrix with the fitted Decision Tree model, Checking the Area Under the Curve for the fitted Decision Tree Model, Visualization of Receiver Operating Characteristic (ROC).\n",
            "\n",
            "Education – University Rankings (Output feature – World Rank)\n",
            "Reading university rankings data from different sources like Shanghai, Times, Reading education expenditure data, Reading country wise university data, Cleaning the data, Filtering the data, Removing inconsistencies within the data, Filling missing values in datasets, Merging ranks and expenditure data, Making column names match within different datasets, Checking correlation between rank and other features, Converting String data values to numeric wherever applicable, Removing unwanted columns in the data, Application of Principal Component Analysis (PCA) for 29 features, Achieved 99% of variance with only 5 Principal Components by visualizing the % variance exhibited cumulatively by the components, Fitted the Logistic Regression and Decision Tree with the Principal Components, Found Decision Tree model as the best model with higher accuracy.\n",
            "\n",
            "Brick & Mortar – Walmart Holiday (Output feature – Is Holiday)\n",
            "Merging Walmart features and stores from 2 different data sources, Dummy encoding of type of stores, Analysing Sales by stores and dates, Applied Logistic Regression and found to be a good fit model with good score.\n",
            "\n",
            "\n",
            "\n",
            "EMPLOYMENT\n",
            "\t-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Sr. Associate Analyst (Developer)\t\tTech Mahindra\t\t\t\t11/2015 - Present\n",
            "\n",
            "QC Automation Tool\n",
            "Application that validates Veeva iPad eDetailers in alignment with a set of guidelines.\n",
            "CSV Upload Tool\n",
            "Application to upload Veeva iPad eDetailers through Veeva Vault to CRM.\n",
            "Auto Upload Tool\n",
            "Application that publishes Veeva iPad eDetailers through Veeva Developer API to CRM.\n",
            "Quality Check\n",
            "Pre-QC and Full-QC review of Veeva iPad eDetailers against a set of guidelines.\n",
            "Report Validation\n",
            "Validation of events triggered through Veeva iPad eDetailers with Salesforce reports.\n",
            "Technologies used\n",
            "PHP, MySQL, CodeIgniter.\n",
            "\n",
            "Software Engineer\t\tLRR Technologies, CallHealth Services\t\t02/2015 - 09/2015\t\n",
            "100 pins\n",
            "Application that allows its users to pin their favourite places.\n",
            "Medical Records Management System\n",
            "Application to maintain medical records of patients.\n",
            "Technologies used\n",
            "PHP, WordPress, MySQL.\n",
            "\n",
            "Sr. PHP Developer\t\tChevronne Softech, Tenazx Inc.\t\t\t09/2013 - 08/2014\n",
            "\n",
            "More Visas ERP\n",
            "Application for overseas career specialist.\n",
            "Banner Maker\n",
            "Application to create banners with various text/image editing features.\n",
            "Restaurant Finder\n",
            "Application to find nearby restaurants and order food.\n",
            "Technologies used\n",
            "PHP, MySQL, jQuery, JavaScript, CodeIgniter.\n",
            "APIs – Factual, Locu, Called.in, Interfax, GeoIP2 JS.\n",
            "\n",
            "PHP Developer\t\t\t\tIntelex Systems\t\t\t\t07/2012 - 04/2013\n",
            "\n",
            "Dice Jobs\n",
            "Modifications and enhancements to UK based job website.\n",
            ".NET Console Application\n",
            "Communicates with web service to add, edit, and delete jobs in Jobg8 Network.\n",
            "Maruti Properties\n",
            "Changes and improvements to real estate application.\n",
            "Technologies used\n",
            "PHP, C#.NET, XML, XSLT.\n",
            "\n",
            "Software Engineer\tWeather Decision Technologies Inc., Norman, OK, USA\t10/2009 - 05/2011\n",
            "\n",
            "Flash Application\n",
            "Allows users to manually set/draw geographical locations on an ESRI map.\n",
            "Plug-in DLL\n",
            "Migrated C/C++ projects from CodeWarrior IDE to Visual Studio 2008 IDE.\n",
            "Lightning Alert Bars\n",
            "Application to show weather forecasts.\n",
            "Technologies used\n",
            "ActionScript 3.0, ArcGIS API for Flex Builder, AMFPHP, PHP, PostgreSQL, PostGIS, XML, Visual Studio 2008, DLL Toys.\t\n",
            "\n",
            "\n",
            "\n",
            "Summer Intern\t\t\t\tAvansic, Tulsa, OK, USA\t\t\t05/2009 - 08/2009\n",
            "\n",
            "Case and Evidence Management System\n",
            "Application to keep track of Forensic cases and evidences.\n",
            "Technologies used\n",
            "PHP, JavaScript\n",
            "\n",
            "Graduate Research Assistant\t\tUniversity of Oklahoma, Norman, OK, USA\t02/2007 - 07/2008\n",
            "\n",
            "Quantitative Geogenome Mineralogy Simulator\n",
            "Application to predict macroscopic mechanical properties such as Young’s modulus, \n",
            "Poisson’s ratio etc. of shale rocks given the mineral composition and porosity.\n",
            "Technologies used\n",
            "Visual Basic 6\n",
            "Department\n",
            "Poro Mechanics Institute, Clients – Halliburton, Chevron, ConocoPhillips, Hydro, Eco Petrol, Saudi-Aramco.\n",
            "\n",
            "KEY TECHNICAL SKILLS\n",
            "\t-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Data Science – \n",
            "Python for Data Science (NumPy, Pandas, Scikit-Learn, Matplotlib, Seaborn, etc.)\n",
            "Statistics, Statistical Inference\n",
            "Exploratory Data Analysis, Data Visualization\n",
            "Machine Learning (Linear Regression, Logistic Regression, Decision Trees, Random Forest, Cross Validation, Confusion Matrix, Principal Component Analysis, K-Nearest Neighbours, Naive Bayes, Support Vector Machines, Clustering, and Time Series)\n",
            "\n",
            "Web Application - PHP, ActionScript, jQuery, HTML, JavaScript, MySQL, PostgreSQL, SQL.\n",
            "\n",
            "EDUCATION\n",
            "\t-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "The University of Oklahoma, USA\t\t2007 – 2009\n",
            "MS in Computer Science. GPA: 3.0/4.0\n",
            "\n",
            "JITS, JNTU\t\t\t\t\t2001 – 2005\n",
            "B.Tech in Computer Science & Engineering with 62.38% (First Class)\n",
            "\n",
            "Intermediate Education (10+2)\t\t\t1999 – 2001\n",
            "MPC stream with 75.5% (Math Score – 83.33%)\n",
            "\n",
            "SSC Class 10\t\t\t\t\t1998 – 1999\n",
            "First class distinction with 93% score in Mathematics\n",
            "\n",
            "\tOTHER INFORMATION\n",
            "\t-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Communication Skills: English (TOEFL Score - 237)\n",
            "Aptitude (GRE Score - 730)\t\t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "st5xrYnyhPka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}